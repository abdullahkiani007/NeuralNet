{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqnOe6Pcc2dQ9wPgGaJsV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahkiani007/NeuralNet/blob/main/predictiveModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKKW7uaimn4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_011Pf7lm0P",
        "outputId": "0ab58472-d910-459e-d8ef-ff19613ef49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample responses from a candidate\n",
        "responses = [\n",
        "    \"I'm a software engineer with a passion for developing innovative programs that expedite the efficiency and effectiveness of organizational success.\",\n",
        "    \"I demonstrated leadership when I led a team project to develop a new company website. I assigned tasks, set deadlines, and ensured that everyone was on track.\",\n",
        "    \"During a team project, we faced a major technical issue. I organized a brainstorming session, and we collectively came up with a solution.\",\n",
        "    \"One of my weaknesses is that I tend to be a perfectionist. I'm working on this by setting realistic goals and timeframes for my tasks.\",\n",
        "    \"You should hire me because I have the skills and experience to make a significant contribution to your company. I'm a fast learner and can quickly adapt to new environments.\"\n",
        "]\n",
        "\n",
        "# Preprocess the responses\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "preprocessed_responses = [preprocess(response) for response in responses]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "from nltk import pos_tag\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Download the necessary resource\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Extract features\n",
        "def extract_features(text):\n",
        "    features = {}\n",
        "\n",
        "    # Word count\n",
        "    features['word_count'] = len(text)\n",
        "\n",
        "    # Sentence count\n",
        "    features['sentence_count'] = len(nltk.sent_tokenize(' '.join(text)))\n",
        "\n",
        "    # Parts of speech\n",
        "    pos_counts = FreqDist(tag for (word, tag) in pos_tag(text))\n",
        "    features['noun_count'] = pos_counts['NN'] + pos_counts['NNS']\n",
        "    features['verb_count'] = pos_counts['VB'] + pos_counts['VBD'] + pos_counts['VBG'] + pos_counts['VBN'] + pos_counts['VBP'] + pos_counts['VBZ']\n",
        "    features['adjective_count'] = pos_counts['JJ'] + pos_counts['JJR'] + pos_counts['JJS']\n",
        "    features['adverb_count'] = pos_counts['RB'] + pos_counts['RBR'] + pos_counts['RBS']\n",
        "\n",
        "    # Sentiment analysis\n",
        "    blob = TextBlob(' '.join(text))\n",
        "    features['polarity'] = blob.sentiment.polarity\n",
        "    features['subjectivity'] = blob.sentiment.subjectivity\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to all responses\n",
        "# print(preprocessed_responses)\n",
        "features = [extract_features(response) for response in preprocessed_responses]\n",
        "print(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIu243fSmxEP",
        "outputId": "ad2a2f53-cf3e-49fc-a760-008070680497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'word_count': 11, 'sentence_count': 1, 'noun_count': 6, 'verb_count': 2, 'adjective_count': 3, 'adverb_count': 0, 'polarity': 0.4, 'subjectivity': 0.5}, {'word_count': 16, 'sentence_count': 1, 'noun_count': 9, 'verb_count': 5, 'adjective_count': 2, 'adverb_count': 0, 'polarity': 0.13636363636363635, 'subjectivity': 0.45454545454545453}, {'word_count': 12, 'sentence_count': 1, 'noun_count': 5, 'verb_count': 4, 'adjective_count': 2, 'adverb_count': 1, 'polarity': 0.03125, 'subjectivity': 0.3}, {'word_count': 10, 'sentence_count': 1, 'noun_count': 4, 'verb_count': 4, 'adjective_count': 1, 'adverb_count': 0, 'polarity': 0.16666666666666666, 'subjectivity': 0.3333333333333333}, {'word_count': 13, 'sentence_count': 1, 'noun_count': 5, 'verb_count': 3, 'adjective_count': 3, 'adverb_count': 2, 'polarity': 0.26117424242424236, 'subjectivity': 0.6073863636363637}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample ratings (to be replaced with actual data)\n",
        "ratings = {\n",
        "    'Overall': [5, 4, 4, 3, 5],\n",
        "    'RecommendHiring': [1, 1, 1, 0, 1],\n",
        "    'Colleague': [4, 4, 4, 3, 5],\n",
        "    'Engaged': [5, 4, 4, 3, 5],\n",
        "    'Excited': [5, 4, 4, 3, 5],\n",
        "    'EyeContact': [5, 4, 4, 3, 5],\n",
        "    'Smiled': [5, 4, 4, 3, 5],\n",
        "    'SpeakingRate': [5, 4, 4, 3, 5],\n",
        "    'NoFillers': [5, 4, 4, 3, 5],\n",
        "    'Friendly': [5, 4, 4, 3, 5],\n",
        "    'Paused': [1, 2, 2, 3, 1],\n",
        "    'EngagingTone': [5, 4, 4, 3, 5],\n",
        "    'StructuredAnswers': [5, 4, 4, 3, 5],\n",
        "    'Calm': [5, 4, 4, 3, 5],\n",
        "    'NotStressed': [5, 4, 4, 3, 5],\n",
        "    'Focused': [5, 4, 4, 3, 5],\n",
        "    'Authentic': [5, 4, 4, 3, 5],\n",
        "    'NotAwkward': [5, 4, 4, 3, 5],\n",
        "    'Total': [90, 76, 76, 57, 90]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "features_df = pd.DataFrame(features)\n",
        "ratings_df = pd.DataFrame(ratings)\n",
        "\n",
        "# Combine features and ratings\n",
        "data = pd.concat([features_df, ratings_df], axis=1)\n",
        "\n",
        "# Train-test split\n",
        "X = data.drop(columns=['Total'])\n",
        "y = data['Total']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Output predictions\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F7AMfcUtauF",
        "outputId": "1dc98e68-723f-40a3-f47d-714e8a306b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[89.07885259]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "turker_score = pd.read_csv('turker_scores_full_interview.csv')\n",
        "new_score = turker_score[turker_score[\"Worker\"] ==\"AGGR\"]\n",
        "\n",
        "new_score = new_score.drop(columns=['Worker'])\n",
        "# print(new_score.columns)\n",
        "\n",
        "# Reset the index and drop the old index\n",
        "new_score = new_score.reset_index(drop=True)\n",
        "\n",
        "print(new_score)\n",
        "new_score.to_csv('new_turker_score.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2e5JsURxHfm",
        "outputId": "66f62413-2dbd-4fbf-f3ec-833dfd54de94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Participant   Overall  RecommendHiring  Colleague   Engaged   Excited  \\\n",
            "0            p1  5.297316         5.106224   5.333004  5.541380  5.043890   \n",
            "1            p3  4.414892         4.433070   5.010430  5.616076  5.601586   \n",
            "2            p4  4.494494         4.530129   4.500707  5.494494  4.261343   \n",
            "3            p5  5.457670         5.571558   5.772488  5.903057  4.707062   \n",
            "4            p6  5.106512         4.831482   4.860595  5.020385  4.648259   \n",
            "..          ...       ...              ...        ...       ...       ...   \n",
            "133        pp83  6.045748         5.806617   6.347873  6.243224  5.806617   \n",
            "134        pp84  5.710073         6.020304   5.437203  5.749959  5.307262   \n",
            "135        pp85  5.626074         5.766592   5.791370  6.375623  5.584830   \n",
            "136        pp86  4.853881         4.700179   4.495230  5.513933  5.137644   \n",
            "137        pp89  4.960084         4.370067   5.143083  5.138736  4.407999   \n",
            "\n",
            "     EyeContact    Smiled  SpeakingRate  NoFillers  Friendly    Paused  \\\n",
            "0      5.866119  3.576160      4.865590   3.771665  5.254784  5.800468   \n",
            "1      5.426861  6.062173      5.016286   3.332458  6.500329  4.791550   \n",
            "2      3.857848  4.852150      4.738000   3.111445  5.369884  5.177447   \n",
            "3      6.694276  3.920479      4.927181   5.881741  5.649119  5.886326   \n",
            "4      4.331805  4.194227      4.174891   3.920329  4.495375  5.027823   \n",
            "..          ...       ...           ...        ...       ...       ...   \n",
            "133    5.847779  6.483032      4.655062   4.838943  6.549279  5.764552   \n",
            "134    5.564999  6.533606      4.656370   5.047772  6.529525  5.912420   \n",
            "135    6.280263  5.050913      4.263639   4.097177  5.970750  5.643748   \n",
            "136    5.892929  4.875432      4.645732   4.126127  5.022182  4.814251   \n",
            "137    3.922369  5.265014      4.599027   3.328301  5.667336  5.904252   \n",
            "\n",
            "     EngagingTone  StructuredAnswers      Calm  NotStressed   Focused  \\\n",
            "0        5.147909           4.891580  5.351075     5.350760  5.845226   \n",
            "1        5.621231           3.912199  4.476537     5.521215  5.549829   \n",
            "2        4.392736           4.688379  5.065190     5.566084  5.324136   \n",
            "3        4.695523           5.582514  6.130488     5.916373  6.322086   \n",
            "4        4.261988           4.826245  5.828977     5.824390  5.619420   \n",
            "..            ...                ...       ...          ...       ...   \n",
            "133      5.801601           4.878478  5.492810     5.391449  6.083629   \n",
            "134      5.625489           4.890114  5.112062     5.750670  5.988186   \n",
            "135      5.239474           4.918227  4.985095     4.998952  6.554104   \n",
            "136      5.208898           4.240302  5.648693     5.939815  5.078459   \n",
            "137      4.906939           4.258525  5.999464     5.698104  5.078843   \n",
            "\n",
            "     Authentic  NotAwkward       Total  \n",
            "0     5.610513    5.477534   93.131196  \n",
            "1     6.014960    4.923550   92.225232  \n",
            "2     5.658364    4.452909   85.535740  \n",
            "3     6.020070    5.629838  100.667850  \n",
            "4     5.371858    5.295977   87.640538  \n",
            "..         ...         ...         ...  \n",
            "133   6.559118    5.840547  104.436358  \n",
            "134   6.248887    5.169949  101.254849  \n",
            "135   6.372852    4.800594   98.320278  \n",
            "136   6.008339    5.154665   91.356689  \n",
            "137   6.177226    5.478425   90.303795  \n",
            "\n",
            "[138 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the prosodic features dataset\n",
        "prosodic_features_df = pd.read_csv('prosodic_features.csv')\n",
        "\n",
        "# Extract participant ID from 'participant&question' column\n",
        "prosodic_features_df['participant'] = prosodic_features_df['participant&question'].str.extract(r'(^P\\d+)')\n",
        "\n",
        "# Drop the 'participant&question' column as it's no longer needed\n",
        "prosodic_features_df = prosodic_features_df.drop(columns=['participant&question'])\n",
        "\n",
        "prosodic_features_df['avgVal3'] = pd.to_numeric(prosodic_features_df['avgVal3'], errors='coerce')\n",
        "prosodic_features_df['avgBand3'] = pd.to_numeric(prosodic_features_df['avgBand3'], errors='coerce')\n",
        "\n",
        "# Fill NaN values with mean\n",
        "prosodic_features_df['avgVal3'] = prosodic_features_df['avgVal3'].fillna(prosodic_features_df['avgVal3'].mean())\n",
        "prosodic_features_df['avgBand3'] = prosodic_features_df['avgBand3'].fillna(prosodic_features_df['avgBand3'].mean())\n",
        "\n",
        "\n",
        "\n",
        "# Group by 'participant' and calculate the mean for each group\n",
        "prosodic_features_avg_df = prosodic_features_df.groupby('participant').mean().reset_index()\n",
        "\n",
        "# Save the processed data to a new CSV file (optional)\n",
        "prosodic_features_avg_df.to_csv('processed_prosodic_features.csv', index=False)\n",
        "\n",
        "# Print the processed DataFrame to verify\n",
        "print(prosodic_features_avg_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgbDvZCF-N-g",
        "outputId": "3f2fef18-e3b0-43d7-b5d8-608ccedabcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  participant   duration    energy     power  min_pitch   max_pitch  \\\n",
            "0          P1  34.186796  0.011510  0.000333  78.064294  340.516454   \n",
            "1         P10  77.378613  0.032118  0.000404  74.787772  345.935347   \n",
            "2         P11  50.431333  0.007220  0.000134  73.605587  384.004524   \n",
            "3         P12  35.910442  0.008005  0.000205  73.706414  326.346399   \n",
            "4         P13  51.049858  0.001618  0.000029  75.141598  332.370097   \n",
            "\n",
            "   mean_pitch   pitch_sd   pitch_abs  pitch_quant  ...  avgDurPause  \\\n",
            "0  129.307639  25.242104  176.176383   121.943026  ...       0.5312   \n",
            "1  112.955696  25.915806  166.265804   106.681483  ...       0.7232   \n",
            "2  186.524402  35.911648  226.353579   183.792011  ...       0.5326   \n",
            "3  181.006693  40.494458  266.110211   184.081501  ...       0.9796   \n",
            "4  181.156105  41.081781  249.154938   189.416587  ...       0.6952   \n",
            "\n",
            "   TotDurPause:3  iInterval  MaxRising:3  MaxFalling:3  AvgTotRis:3  \\\n",
            "0        17.9984       87.8     211.4666      186.2474      20.4186   \n",
            "1        39.8548      159.8     231.7972      222.0450      23.4998   \n",
            "2        25.7530      127.8     176.2874      203.0714      24.3098   \n",
            "3        24.3694       94.8     152.8112      148.5378      25.6070   \n",
            "4        25.0772      118.6     186.6008      166.8634      31.6820   \n",
            "\n",
            "   AvgTotFall:3  numRising      numFall  loudness  \n",
            "0       13.8120       59.2  2885.361924       NaN  \n",
            "1       17.2176      114.4  4560.598782       NaN  \n",
            "2       15.5036       84.4  4359.223573       NaN  \n",
            "3       27.0372       53.4  4160.100665       NaN  \n",
            "4       19.6138       77.4   420.371424       NaN  \n",
            "\n",
            "[5 rows x 60 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ws5A93aeJBir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "ratings_df = pd.read_csv('new_turker_score.csv')\n",
        "lexical_features_df = pd.read_csv('interviewee_transcript_analysis_results.csv')\n",
        "prosodic_features_df = pd.read_csv('processed_prosodic_features.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Drop the 'Unnamed: 0' column from all DataFrames if it exists\n",
        "ratings_df = ratings_df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "lexical_features_df = lexical_features_df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "prosodic_features_df = prosodic_features_df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "\n",
        "# Ensure the 'Participant' column is the key for merging\n",
        "ratings_df.rename(columns={'Participant': 'participant'}, inplace=True)\n",
        "lexical_features_df.rename(columns={'Participant': 'participant'}, inplace=True)\n",
        "prosodic_features_df.rename(columns={'participant&question': 'participant'}, inplace=True)\n",
        "\n",
        "prosodic_features_df['participant'] = prosodic_features_df['participant'].str.lower()\n",
        "\n",
        "# Merge the datasets on 'participant'\n",
        "combined_df = pd.merge(ratings_df, lexical_features_df, on='participant', how='inner')\n",
        "combined_df = pd.merge(combined_df, prosodic_features_df, on='participant', how='inner')\n",
        "combined_df = combined_df.drop(columns=[\"loudness\"])\n",
        "# Check the combined DataFrame\n",
        "\n",
        "print(\"prosodic shape\", prosodic_features_df.shape)\n",
        "print(\"lexical shape\", lexical_features_df.shape)\n",
        "print(\"ratings shape\", ratings_df.shape)\n",
        "\n",
        "print(\"Combined DataFrame:\")\n",
        "print(combined_df.shape)\n",
        "# combined_df.to_csv('combined_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7hX6d2Z7BH8",
        "outputId": "136e30b2-69b3-4ba7-a44c-91a194cc00cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prosodic shape (69, 60)\n",
            "lexical shape (138, 22)\n",
            "ratings shape (138, 20)\n",
            "Combined DataFrame:\n",
            "(69, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target variable\n",
        "target = 'RecommendHiring'\n",
        "\n",
        "# Drop the columns not needed for features\n",
        "X = combined_df.drop(columns=['participant', 'RecommendHiring'])\n",
        "\n",
        "# Target variable\n",
        "y = combined_df[target]\n"
      ],
      "metadata": {
        "id": "jJDZHJEBK2Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ETHePSiCK7Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBHfJxHTMD0d",
        "outputId": "4a649c32-554e-4e60-854f-201138a6a561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Overall', 'Colleague', 'Engaged', 'Excited', 'EyeContact', 'Smiled',\n",
            "       'SpeakingRate', 'NoFillers', 'Friendly', 'Paused', 'EngagingTone',\n",
            "       'StructuredAnswers', 'Calm', 'NotStressed', 'Focused', 'Authentic',\n",
            "       'NotAwkward', 'Total', 'Filler Words', 'I Count', 'We Count',\n",
            "       'They Count', 'Verb Count', 'Adverb Count', 'Preposition Count',\n",
            "       'Conjunction Count', 'Positive Emotion Words', 'Negative Emotion Words',\n",
            "       'Anxiety Words', 'Anger Words', 'Sadness Words', 'Cognitive Words',\n",
            "       'Inhibition Words', 'Perceptual Words', 'Work-Related Words',\n",
            "       'Articles', 'Negations', 'Quantifiers', 'Tentative Language',\n",
            "       'duration', 'energy', 'power', 'min_pitch', 'max_pitch', 'mean_pitch',\n",
            "       'pitch_sd', 'pitch_abs', 'pitch_quant', 'pitchUvsVRatio', 'Time:8',\n",
            "       'iDifference', 'diffPitchMaxMin', 'diffPitchMaxMean',\n",
            "       'diffPitchMaxMode', 'intensityMin', 'intensityMax', 'intensityMean',\n",
            "       'intensitySD', 'intensityQuant', 'diffIntMaxMin', 'diffIntMaxMean',\n",
            "       'diffIntMaxMode', 'avgVal1', 'avgVal2', 'avgVal3', 'avgBand1',\n",
            "       'avgBand2', 'avgBand3', 'fmean1', 'fmean2', 'fmean3', 'f2meanf1',\n",
            "       'f3meanf1', 'f1STD', 'f2STD', 'f3STD', 'f2STDf1', 'f2STDf2', 'jitter',\n",
            "       'shimmer', 'jitterRap', 'meanPeriod', 'percentUnvoiced',\n",
            "       'numVoiceBreaks', 'PercentBreaks', 'speakRate', 'numPause',\n",
            "       'maxDurPause', 'avgDurPause', 'TotDurPause:3', 'iInterval',\n",
            "       'MaxRising:3', 'MaxFalling:3', 'AvgTotRis:3', 'AvgTotFall:3',\n",
            "       'numRising', 'numFall'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "RtoayPHTK-P4",
        "outputId": "2a8da17f-b8a0-4f3d-ccb0-938f8465ed87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2Fv1r1ZMepE",
        "outputId": "5e8eb368-02b9-4f80-9c32-d536659aeb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 11.965809574362817\n",
            "R^2 Score: -23.25532127622812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f'Cross-validated MSE: {-cv_scores.mean()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z_bxxmZM_sV",
        "outputId": "ffddad68-2a4a-4691-e4be-9af1eea2fb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 43.8048337568719\n",
            "R^2 Score: -87.79468703071596\n",
            "Cross-validated MSE: 0.1787672932324542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize and train the RandomForest model\n",
        "rf_model = RandomForestRegressor()\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f'Random Forest Mean Squared Error: {mse_rf}')\n",
        "print(f'Random Forest R^2 Score: {r2_rf}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMzkzEe4NSGR",
        "outputId": "ff4fddcb-d517-4b20-904a-588c3c659a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Squared Error: 0.07557677153825769\n",
            "Random Forest R^2 Score: 0.8468019348554484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_rf)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5RhT2xePMuA",
        "outputId": "ea09970e-a9ae-490d-c7ab-755a534b00a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.75572597 5.10637257 4.96654198 4.95126741 4.41825861 5.80811498\n",
            " 3.90308169 3.77526353 4.71704473 4.03868326 4.41796798 4.97090471\n",
            " 5.11414636 5.46628648]\n",
            "22    3.189661\n",
            "0     5.106224\n",
            "47    4.475493\n",
            "4     4.831482\n",
            "53    4.298151\n",
            "18    6.015717\n",
            "10    4.325522\n",
            "33    3.560751\n",
            "44    4.831596\n",
            "12    3.963723\n",
            "31    4.527523\n",
            "9     4.925221\n",
            "59    4.705135\n",
            "5     5.473467\n",
            "Name: RecommendHiring, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained Random Forest model\n",
        "# joblib.dump(rf_model, 'random_forest_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBSHM3FOQFzp",
        "outputId": "1babd62b-d23a-4b9e-e4dd-7f692f708f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load the model and scaler\n",
        "model = joblib.load('random_forest_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')  # Load the scaler if you used one\n",
        "\n",
        "# Create a DataFrame with new data\n",
        "# Ensure the column names match those used during training\n",
        "X_new = pd.DataFrame({\n",
        "    'Overall': [2],\n",
        "    'Colleague': [1],\n",
        "    'Engaged': [3],\n",
        "    'Excited': [2],\n",
        "    'EyeContact': [1],\n",
        "    'Smiled': [0],\n",
        "    'SpeakingRate': [1.2],\n",
        "    'NoFillers': [3],\n",
        "    'Friendly': [1],\n",
        "    'Paused': [2],\n",
        "    'EngagingTone': [0],\n",
        "    'StructuredAnswers': [1],\n",
        "    'Calm': [0],\n",
        "    'NotStressed': [1],\n",
        "    'Focused': [0],\n",
        "    'Authentic': [1],\n",
        "    'NotAwkward': [0],\n",
        "    'Total': [30],\n",
        "    'Filler Words': [5],\n",
        "    'I Count': [2],\n",
        "    'We Count': [1],\n",
        "    'They Count': [0],\n",
        "    'Verb Count': [10],\n",
        "    'Adverb Count': [4],\n",
        "    'Preposition Count': [6],\n",
        "    'Conjunction Count': [3],\n",
        "    'Positive Emotion Words': [7],\n",
        "    'Negative Emotion Words': [2],\n",
        "    'Anxiety Words': [1],\n",
        "    'Anger Words': [0],\n",
        "    'Sadness Words': [1],\n",
        "    'Cognitive Words': [8],\n",
        "    'Inhibition Words': [2],\n",
        "    'Perceptual Words': [5],\n",
        "    'Work-Related Words': [4],\n",
        "    'Articles': [12],\n",
        "    'Negations': [1],\n",
        "    'Quantifiers': [3],\n",
        "    'Tentative Language': [2],\n",
        "    'duration': [120.0],\n",
        "    'energy': [1.5],\n",
        "    'power': [0.5],\n",
        "    'min_pitch': [100.0],\n",
        "    'max_pitch': [300.0],\n",
        "    'mean_pitch': [200.0],\n",
        "    'pitch_sd': [20.0],\n",
        "    'pitch_abs': [50.0],\n",
        "    'pitch_quant': [30.0],\n",
        "    'pitchUvsVRatio': [0.6],\n",
        "    'Time:8': [0.3],\n",
        "    'iDifference': [0.1],\n",
        "    'diffPitchMaxMin': [200.0],\n",
        "    'diffPitchMaxMean': [100.0],\n",
        "    'diffPitchMaxMode': [50.0],\n",
        "    'intensityMin': [0.4],\n",
        "    'intensityMax': [1.2],\n",
        "    'intensityMean': [0.8],\n",
        "    'intensitySD': [0.2],\n",
        "    'intensityQuant': [0.5],\n",
        "    'diffIntMaxMin': [0.8],\n",
        "    'diffIntMaxMean': [0.4],\n",
        "    'diffIntMaxMode': [0.3],\n",
        "    'avgVal1': [0.5],\n",
        "    'avgVal2': [0.6],\n",
        "    'avgVal3': [0.7],\n",
        "    'avgBand1': [0.4],\n",
        "    'avgBand2': [0.5],\n",
        "    'avgBand3': [0.6],\n",
        "    'fmean1': [0.3],\n",
        "    'fmean2': [0.4],\n",
        "    'fmean3': [0.5],\n",
        "    'f2meanf1': [0.2],\n",
        "    'f3meanf1': [0.3],\n",
        "    'f1STD': [0.1],\n",
        "    'f2STD': [0.2],\n",
        "    'f3STD': [0.3],\n",
        "    'f2STDf1': [0.1],\n",
        "    'f2STDf2': [0.2],\n",
        "    'jitter': [0.05],\n",
        "    'shimmer': [0.1],\n",
        "    'jitterRap': [0.02],\n",
        "    'meanPeriod': [0.3],\n",
        "    'percentUnvoiced': [0.1],\n",
        "    'numVoiceBreaks': [2],\n",
        "    'PercentBreaks': [0.15],\n",
        "    'speakRate': [150.0],\n",
        "    'numPause': [3],\n",
        "    'maxDurPause': [0.5],\n",
        "    'avgDurPause': [0.3],\n",
        "    'TotDurPause:3': [0.8],\n",
        "    'iInterval': [0.1],\n",
        "    'MaxRising:3': [0.2],\n",
        "    'MaxFalling:3': [0.3],\n",
        "    'AvgTotRis:3': [0.2],\n",
        "    'AvgTotFall:3': [0.3],\n",
        "    'numRising': [5],\n",
        "    'numFall': [3]\n",
        "})\n",
        "\n",
        "# Preprocess the new data\n",
        "X_new_scaled = scaler.transform(X_new)  # Apply scaling if needed\n",
        "\n",
        "# Predict using the trained model\n",
        "predictions = model.predict(X_new_scaled)\n",
        "\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWa8eQEkSr2K",
        "outputId": "70e51d83-d9f0-414f-b588-36fb5a4791b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.64978231]\n"
          ]
        }
      ]
    }
  ]
}