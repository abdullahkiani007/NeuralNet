{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahkiani007/NeuralNet/blob/main/convet_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZnfkVn8Eyk4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dINZ9PhpFnEy",
        "outputId": "12181d27-e099-4b04-ef3d-946804ed150b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12500/12500 [00:14<00:00, 863.64it/s]\n",
            "100%|██████████| 12501/12501 [00:15<00:00, 812.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cats: 12500\n",
            "Dogs: 12500\n"
          ]
        }
      ],
      "source": [
        "# Data Preprocessing\n",
        "REBUILDING_DATA = True\n",
        "\n",
        "class DogsVsCats():\n",
        "  IMG_SIZE = 50\n",
        "  CATS = \"/content/train/cats\"\n",
        "  DOGS = \"/content/train/dogs\"\n",
        "  LABELS = {CATS: 0, DOGS: 1}\n",
        "  trainingData = []\n",
        "  catCount = 0\n",
        "  dogCount = 0\n",
        "\n",
        "  def make_training_data(self):\n",
        "    for label in self.LABELS:\n",
        "\n",
        "      for f in tqdm(os.listdir(label)):\n",
        "\n",
        "        try:\n",
        "          path = os.path.join(label, f)\n",
        "          img = cv2.imread(path, cv2.IMREAD_GRAYSCALE )\n",
        "          img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "          # img = np.expand_dims(img, axis=2)\n",
        "\n",
        "          # np.eye(2)[0] --> create one hot vector --> [1,0]\n",
        "          label_encoded = np.eye(2)[self.LABELS[label]]\n",
        "          self.trainingData.append( [np.array(img), label_encoded] )\n",
        "          if label == self.CATS:\n",
        "            self.catCount += 1\n",
        "          elif label == self.DOGS:\n",
        "            self.dogCount += 1\n",
        "        except Exception as e:\n",
        "          pass\n",
        "    np.random.shuffle(self.trainingData)\n",
        "\n",
        "    training_images = np.array([data[0] for data in self.trainingData])\n",
        "    training_labels = np.array([data[1] for data in self.trainingData])\n",
        "\n",
        "    # Save images and labels separately\n",
        "    np.save(\"training_data_images.npy\", training_images , allow_pickle=True)\n",
        "    np.save(\"training_data_labels.npy\", training_labels , allow_pickle=True)\n",
        "\n",
        "    print(\"Cats:\", self.catCount)\n",
        "    print(\"Dogs:\", self.dogCount)\n",
        "\n",
        "if REBUILDING_DATA:\n",
        "  dogsVscats = DogsVsCats()\n",
        "  dogsVscats.make_training_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQHss4N0nRhI",
        "outputId": "0e88bb7e-d91b-4ff9-c6c3-5c4afb12e732"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.eye(2)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g8Rtfp9tFHo",
        "outputId": "9daf6384-6bb0-4fe2-dee3-6fc863a8ce65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(os.path.exists(\"trainingData.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbDn5GT4G0pi",
        "outputId": "cbe4af85-d239-47fb-870d-1505b73d7623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images shape: (25000, 50, 50)\n",
            "Labels shape: (25000, 2)\n",
            "Merged training data shape: (25000,)\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have loaded your images and labels separately\n",
        "training_data_images = np.load(\"training_data_images.npy\", allow_pickle=True)\n",
        "training_data_labels = np.load(\"training_data_labels.npy\", allow_pickle=True)\n",
        "\n",
        "# Verify shapes before stacking\n",
        "print(f\"Images shape: {training_data_images.shape}\")\n",
        "print(f\"Labels shape: {training_data_labels.shape}\")\n",
        "\n",
        "# Stack images and labels in a tuple format\n",
        "# Use 'object' directly instead of 'np.object'\n",
        "training_data = np.empty((len(training_data_images),), dtype=object)\n",
        "for i in range(len(training_data_images)):\n",
        "    training_data[i] = (training_data_images[i], training_data_labels[i])\n",
        "\n",
        "\n",
        "# Verify the shape of the merged array\n",
        "print(f\"Merged training data shape: {training_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "EoWuxdb0isXC",
        "outputId": "a3d13b96-93cb-4043-a417-3c29b1f95ea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([[164, 165, 156, ..., 194, 199, 196],\n",
            "       [148, 155, 150, ..., 185, 202, 203],\n",
            "       [154, 157, 139, ..., 186, 192, 203],\n",
            "       ...,\n",
            "       [ 97,  81,  59, ...,  77, 172, 172],\n",
            "       [101,  81,  83, ..., 169, 172, 164],\n",
            "       [108,  79,  60, ..., 185, 166, 165]], dtype=uint8), array([1., 0.]))\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(training_data[0])\n",
        "plt.imshow(training_data[0][0] ,cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM-nZcwZtXR-"
      },
      "outputs": [],
      "source": [
        "np.save(\"training_data.npy\", training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyW88H8mJkch"
      },
      "outputs": [],
      "source": [
        "training_data = np.load(\"training_data.npy\" ,allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "TXo8HXczdG48",
        "outputId": "172f068c-aff8-4380-d491-79899f034079"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a0a29c9-e90a-4af3-90cb-aeefe6633c2a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a0a29c9-e90a-4af3-90cb-aeefe6633c2a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving training_data.npy to training_data.npy\n"
          ]
        }
      ],
      "source": [
        "#Mount your Google Drive files Following code make mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        " #   Now upload the kaggle.json file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload() #this will prompt you to upload the kaggle.json\n",
        "\n",
        "  #  make sure kaggle.json file is present\n",
        "!ls -lha kaggle.json\n",
        "\n",
        "#    Install kaggle API client\n",
        "!pip install -q kaggle\n",
        "\n",
        "#kaggle API client expects the file to be in ~/.kaggle\n",
        "#so move it there\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "#we need to set permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "#check your directory before downloading the datasets\n",
        "!pwd\n",
        "\n",
        "#list all available datasets\n",
        "!kaggle datasets list\n",
        "\n",
        "#download the required dataset from kaggle\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "\n",
        "#If your file is a zip file you can unzip with the following code\n",
        "!unzip dogs-vs-cats.zip\n",
        "\n",
        "!unzip train.zip\n",
        "\n",
        "# Create directories\n",
        "!mkdir -p train/cats train/dogs\n",
        "\n",
        "# Move cat images\n",
        "!find . -type f -name 'cat*.*' -exec mv {} train/cats/ \\;\n",
        "\n",
        "# Move dog images\n",
        "!find . -type f -name 'dog*.*' -exec mv {} train/dogs/ \\;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjPNjaEzg2sr",
        "outputId": "220a97a5-90ca-47c5-b5ee-71c8e338bfc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9R-uq69lIPK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "        self._to_linear = None\n",
        "\n",
        "        x = torch.rand(50,50)\n",
        "        self.fc1 = None  # Initialize later\n",
        "        self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "\n",
        "    def convs(self,x):\n",
        "      x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "      x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "      x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "\n",
        "      if self.fc1 is None:\n",
        "        x_shape = x[0].shape\n",
        "        self._to_linear = x_shape[0] * x_shape[1] * x_shape[2]\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x,dim=1)\n",
        "\n",
        "net = Net()\n",
        "input_image = torch.randn(1, 1, 50, 50)\n",
        "output = net(input_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekgjAK3twzRq",
        "outputId": "4884fca6-32c4-40bf-e6dc-7e1ec978dfe0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-ae3dd2871f8f>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "\n",
        "Y = torch.Tensor([i[1] for i in training_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-bEL6i8kNl4"
      },
      "outputs": [],
      "source": [
        "VAL_PCT = 0.1\n",
        "val_size = int(len(X)* VAL_PCT)\n",
        "\n",
        "train_x = X[:-val_size]\n",
        "train_y = Y[:-val_size]\n",
        "\n",
        "test_x = X[-val_size:]\n",
        "test_y = X[-val_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J52tT36m4wk",
        "outputId": "66b61e83-e150-4bc1-966f-fce9a6f2372f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [02:04<00:00,  1.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1, Loss: 0.22311797738075256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for i in tqdm(range(0, len(train_x), BATCH_SIZE)):\n",
        "    batch_x = train_x[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
        "    batch_y = train_y[i:i+BATCH_SIZE]\n",
        "    net.zero_grad()\n",
        "    outputs = net(batch_x)\n",
        "    loss = loss_function(outputs, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xNl80hdXkrij",
        "outputId": "983e062a-eb26-456b-f282-adc19d8c94f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (100) must match the size of tensor b (50) at non-singleton dimension 2",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5e8f2db1a838>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Update the correct count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Calculate the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (50) at non-singleton dimension 2"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 1\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(0, len(test_x), BATCH_SIZE)):\n",
        "        batch_x = test_x[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "        batch_y = test_y[i:i+BATCH_SIZE]\n",
        "        outputs = net(batch_x)\n",
        "\n",
        "        # Get the predicted class\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Update the total count\n",
        "        total += batch_y.size(0)\n",
        "        print(outputs)\n",
        "\n",
        "        # Update the correct count\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the {total} test images: {accuracy:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3oxCLgb4P9g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tqdm\n",
        "\n",
        "features= pd.read_csv(\"interview_transcripts_by_turkers.csv\")\n",
        "turker_score = pd.read_csv('turker_scores_full_interview.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qSdTk_6rCGZ",
        "outputId": "4f67c8b6-dd3c-4c69-ea53-58b49eee4815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Top Feature 1  Top Feature 2  Top Feature 3  Top Feature 4  Top Feature 5  \\\n",
            "0            NaN            NaN            NaN            NaN            NaN   \n",
            "1            NaN            NaN            NaN            NaN            NaN   \n",
            "2            NaN            NaN            NaN            NaN            NaN   \n",
            "3            NaN            NaN            NaN            NaN            NaN   \n",
            "4            NaN            NaN            NaN            NaN            NaN   \n",
            "5            NaN            NaN            NaN            NaN            NaN   \n",
            "6            NaN            NaN            NaN            NaN            NaN   \n",
            "\n",
            "   Top Feature 6  Top Feature 7  \n",
            "0            NaN            NaN  \n",
            "1            NaN            NaN  \n",
            "2            NaN            NaN  \n",
            "3            NaN            NaN  \n",
            "4            NaN            NaN  \n",
            "5            NaN            NaN  \n",
            "6            NaN            NaN  \n"
          ]
        }
      ],
      "source": [
        "trait_result_df = pd.DataFrame(features[:7], columns=['Top Feature 1', 'Top Feature 2', 'Top Feature 3',\n",
        "                                                          'Top Feature 4', 'Top Feature 5', 'Top Feature 6',\n",
        "                                                          'Top Feature 7'])\n",
        "print(trait_result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBaHWoEBsKMa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yz9zJ39rNbq",
        "outputId": "7f70f6e1-778d-4b3f-9086-7b47065e1656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RangeIndex(start=0, stop=1378, step=1)\n",
            "    Participant   Overall  RecommendHiring  Colleague   Engaged   Excited  \\\n",
            "0            p1  5.255257         5.011803   5.259223  5.615709  5.227099   \n",
            "1           p10  4.636124         4.606595   4.623098  4.868082  4.153772   \n",
            "2           p11  5.001159         4.503645   4.759689  4.995317  4.144196   \n",
            "3           p12  5.337614         5.325025   5.811300  5.607812  5.258058   \n",
            "4           p13  4.361250         4.480614   4.476516  4.733128  3.064390   \n",
            "..          ...       ...              ...        ...       ...       ...   \n",
            "133        pp83  5.893972         5.978513   6.594208  6.138136  5.978513   \n",
            "134        pp84  5.634453         6.002256   5.493023  5.527773  5.589696   \n",
            "135        pp85  5.402897         5.640732   5.754597  6.486180  5.842759   \n",
            "136        pp86  4.983765         4.855575   4.499470  5.501548  5.237516   \n",
            "137        pp89  4.884454         4.485563   5.127009  5.126526  4.489778   \n",
            "\n",
            "     EyeContact    Smiled  SpeakingRate  NoFillers  Friendly    Paused  \\\n",
            "0      5.874013  3.508462      5.207288   3.419074  5.250532  5.755608   \n",
            "1      4.629558  5.319890      5.225041   2.642020  5.749756  5.846101   \n",
            "2      3.625478  4.601409      5.543940   3.026714  4.162478  5.868843   \n",
            "3      5.254583  6.616149      5.610675   4.996012  6.484779  5.600663   \n",
            "4      4.867039  3.931837      4.301333   3.641058  4.124475  5.983039   \n",
            "..          ...       ...           ...        ...       ...       ...   \n",
            "133    5.871975  6.498115      4.878340   4.426549  6.616587  5.640506   \n",
            "134    5.173889  6.503734      5.045152   4.894197  6.503281  5.656936   \n",
            "135    6.142251  5.005657      4.168182   3.899686  6.107861  5.293750   \n",
            "136    5.876992  4.875048      4.932859   3.902903  4.891354  5.646028   \n",
            "137    3.658041  4.918335      4.816559   3.147589  5.629704  5.878250   \n",
            "\n",
            "     EngagingTone  StructuredAnswers      Calm  NotStressed   Focused  \\\n",
            "0        5.127545           4.765731  5.150119     5.150084  5.982803   \n",
            "1        5.091012           3.397329  4.049465     4.282546  5.474210   \n",
            "2        4.380750           4.757163  5.003232     5.195944  5.968642   \n",
            "3        5.494710           4.257661  5.800292     5.948979  5.829398   \n",
            "4        2.440885           4.657340  5.607742     5.259750  5.973250   \n",
            "..            ...                ...       ...          ...       ...   \n",
            "133      5.866845           4.542053  5.054757     5.265717  6.231514   \n",
            "134      5.736165           4.543346  4.679118     5.638963  6.220910   \n",
            "135      5.137719           4.435359  4.887233     4.999884  6.728234   \n",
            "136      5.467655           4.471145  5.738744     5.993313  5.342051   \n",
            "137      5.100771           4.028725  6.111052     5.744234  5.008760   \n",
            "\n",
            "     Authentic  NotAwkward       Total  \n",
            "0     5.845613    5.164170   92.570133  \n",
            "1     5.869321    3.904469   84.368388  \n",
            "2     5.768732    4.605246   85.912577  \n",
            "3     6.332433    4.860928  100.427071  \n",
            "4     5.659596    3.772622   81.335866  \n",
            "..         ...         ...         ...  \n",
            "133   6.617680    5.648950  103.742929  \n",
            "134   6.249876    5.018883  100.111650  \n",
            "135   6.485872    4.644510   97.063364  \n",
            "136   6.000927    5.239407   93.456299  \n",
            "137   6.241914    5.497603   89.894866  \n",
            "\n",
            "[138 rows x 20 columns]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Am76blgswGE",
        "outputId": "217978c9-2fef-4d13-c5d8-3e47b3c24ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top features for RecommendHiring: ['Engaged', 'We Count', 'Filler Words']\n",
            "Top features for Overall: ['Engaged', 'Speaking Rate', 'Filler Words']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example MI scores (replace this with loading your actual MI scores DataFrame)\n",
        "data = {\n",
        "    'Trait': ['Filler Words', 'We Count', 'Engaged', 'Smiled', 'Speaking Rate'],\n",
        "    'Overall': [0.007324734, 0.0, 0.034081128, 0.0, 0.022271921],\n",
        "    'RecommendHiring': [0.067357953, 0.110020891, 0.11135889, 0.0, 0.0],\n",
        "    'Colleague': [0.060976955, 0.015240135, 0.015240135, 0.0, 0.0],\n",
        "    'Engaged': [0.034081128, 0.019612884, 0.019612884, 0.111061511, 0.0],\n",
        "    'Excited': [0.0, 0.11135889, 0.099627234, 0.111061511, 0.107052822],\n",
        "}\n",
        "\n",
        "# Create DataFrame from the data (replace `data` with your actual DataFrame)\n",
        "mi_scores = pd.DataFrame(data)\n",
        "\n",
        "# Function to select top features based on MI scores for a specific outcome\n",
        "def select_top_features(mi_scores_df, outcome_column, top_n=5):\n",
        "    # Sort by MI score for the specified outcome column\n",
        "    sorted_features = mi_scores_df.sort_values(by=outcome_column, ascending=False)\n",
        "\n",
        "    # Select top N features based on MI score\n",
        "    top_features = sorted_features.head(top_n)['Trait'].tolist()\n",
        "\n",
        "    return top_features\n",
        "\n",
        "# Example usage: Select top features for 'RecommendHiring'\n",
        "top_features_recommend_hiring = select_top_features(mi_scores, 'RecommendHiring', top_n=3)\n",
        "print(\"Top features for RecommendHiring:\", top_features_recommend_hiring)\n",
        "\n",
        "# Example usage: Select top features for 'Overall'\n",
        "top_features_overall = select_top_features(mi_scores, 'Overall', top_n=3)\n",
        "print(\"Top features for Overall:\", top_features_overall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxAnfyLJ1FdT",
        "outputId": "56821f3a-803e-49a2-b3de-a94c09f617e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from praat-parselmouth) (1.25.2)\n",
            "Installing collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install praat-parselmouth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sr6n64e3L8J",
        "outputId": "4e55ce60-ba1d-41ca-c01f-bb0e9c2178de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install sounddevice scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOC0oHFe35ps"
      },
      "outputs": [],
      "source": [
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(audio_path):\n",
        "    sound = parselmouth.Sound(audio_path)\n",
        "    audio_file_name = os.path.basename(audio_path)  # Extract the audio file name without path\n",
        "\n",
        "    # Duration\n",
        "    duration = call(sound, \"Get total duration\")\n",
        "\n",
        "    # Pitch (F0)\n",
        "    pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
        "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
        "    min_pitch = call(pitch, \"Get minimum\", 0, 0, \"Hertz\")\n",
        "    max_pitch = call(pitch, \"Get maximum\", 0, 0, \"Hertz\")\n",
        "    pitch_sd = call(pitch, \"Get standard deviation\", 0, 0, \"Hertz\")\n",
        "    pitch_range = max_pitch - min_pitch\n",
        "\n",
        "    # Intensity\n",
        "    intensity = call(sound, \"To Intensity\", 75, 0.0)\n",
        "    mean_intensity = call(intensity, \"Get mean\", 0, 0, \"dB\")\n",
        "    min_intensity = call(intensity, \"Get minimum\", 0, 0)\n",
        "    max_intensity = call(intensity, \"Get maximum\", 0, 0)\n",
        "    intensity_sd = call(intensity, \"Get standard deviation\", 0, 0, \"dB\")\n",
        "    intensity_range = max_intensity - min_intensity\n",
        "\n",
        "    # Formants\n",
        "    formant = call(sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 50)\n",
        "    f1_mean = call(formant, \"Get mean\", 1, 0, 0, \"Hertz\")\n",
        "    f2_mean = call(formant, \"Get mean\", 2, 0, 0, \"Hertz\")\n",
        "    f3_mean = call(formant, \"Get mean\", 3, 0, 0, \"Hertz\")\n",
        "    f1_sd = call(formant, \"Get standard deviation\", 1, 0, 0, \"Hertz\")\n",
        "    f2_sd = call(formant, \"Get standard deviation\", 2, 0, 0, \"Hertz\")\n",
        "    f3_sd = call(formant, \"Get standard deviation\", 3, 0, 0, \"Hertz\")\n",
        "\n",
        "    # Bandwidth\n",
        "    f1_bw = call(formant, \"Get bandwidth at time\", 1, 0.0, \"Hertz\")\n",
        "    f2_bw = call(formant, \"Get bandwidth at time\", 2, 0.0, \"Hertz\")\n",
        "    f3_bw = call(formant, \"Get bandwidth at time\", 3, 0.0, \"Hertz\")\n",
        "    f1_f2_ratio_mean = f2_mean / f1_mean\n",
        "    f1_f3_ratio_mean = f3_mean / f1_mean\n",
        "    f1_f2_ratio_sd = f2_sd / f1_mean\n",
        "    f1_f3_ratio_sd = f3_sd / f1_mean\n",
        "\n",
        "    # Jitter and Shimmer\n",
        "    point_process = call(sound, \"To PointProcess (periodic, cc)\", 75, 600)\n",
        "    jitter = call(point_process, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "    shimmer = call(point_process, \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.0)  # Added Maximum amplitude factor\n",
        "\n",
        "    # Voicing\n",
        "    voiced_frames = call(pitch, \"Count voiced frames\")\n",
        "    total_frames = call(pitch, \"Get number of frames\")\n",
        "    percent_unvoiced = 100 * (total_frames - voiced_frames) / total_frames\n",
        "\n",
        "    # Breaks and Pauses\n",
        "    # Adjusted to avoid using unavailable commands\n",
        "    breaks = call(point_process, \"Get number of voice breaks\")\n",
        "    longest_pause = call(point_process, \"Get maximum voice break\")\n",
        "    total_pause_duration = sum(call(point_process, \"Get voice break\", i) for i in range(1, breaks + 1))\n",
        "    avg_pause_duration = total_pause_duration / breaks if breaks != 0 else 0\n",
        "\n",
        "    features = {\n",
        "        'id': audio_file_name,  # The participant ID as the filename\n",
        "        'duration': duration,\n",
        "        'mean_pitch': mean_pitch,\n",
        "        'min_pitch': min_pitch,\n",
        "        'max_pitch': max_pitch,\n",
        "        'pitch_range': pitch_range,\n",
        "        'pitch_sd': pitch_sd,\n",
        "        'mean_intensity': mean_intensity,\n",
        "        'min_intensity': min_intensity,\n",
        "        'max_intensity': max_intensity,\n",
        "        'intensity_range': intensity_range,\n",
        "        'intensity_sd': intensity_sd,\n",
        "        'f1_mean': f1_mean,\n",
        "        'f2_mean': f2_mean,\n",
        "        'f3_mean': f3_mean,\n",
        "        'f1_sd': f1_sd,\n",
        "        'f2_sd': f2_sd,\n",
        "        'f3_sd': f3_sd,\n",
        "        'f1_bw': f1_bw,\n",
        "        'f2_bw': f2_bw,\n",
        "        'f3_bw': f3_bw,\n",
        "        'f1_f2_ratio_mean': f1_f2_ratio_mean,\n",
        "        'f1_f3_ratio_mean': f1_f3_ratio_mean,\n",
        "        'f1_f2_ratio_sd': f1_f2_ratio_sd,\n",
        "        'f1_f3_ratio_sd': f1_f3_ratio_sd,\n",
        "        'jitter': jitter,\n",
        "        'shimmer': shimmer,\n",
        "        'percent_unvoiced': percent_unvoiced,\n",
        "        'num_voice_breaks': breaks,\n",
        "        'percent_breaks': 100 * breaks / total_frames if total_frames > 0 else 0,\n",
        "        'max_dur_pause': longest_pause,\n",
        "        'avg_dur_pause': avg_pause_duration\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "def write_features_to_csv(features_list, output_csv):\n",
        "    df = pd.DataFrame(features_list)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "audio_files = os.listdir(\"audio_files/Audio\")\n",
        "all_features = []\n",
        "\n",
        "for audio_file in audio_files:\n",
        "    audio_path = os.path.join(\"audio_files/Audio\", audio_file)\n",
        "    features = extract_features(audio_path)\n",
        "    all_features.append(features)\n",
        "\n",
        "output_csv = \"all_features.csv\"\n",
        "write_features_to_csv(all_features, output_csv)\n",
        "\n",
        "print(\"All features have been written to the CSV file.\")\n"
      ],
      "metadata": {
        "id": "byU5EzYD7nbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYx1O+NKvGGWchjyx17I4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}